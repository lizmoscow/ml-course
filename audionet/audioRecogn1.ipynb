{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "audioRecogn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "TDb4fz2WmcOx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "da45702b-f573-4894-b456-17f447ec112b"
   },
   "source": [
    "#Was created and launched on collab https://colab.research.google.com/drive/1_TdO-FcP1v4V9ltkZ-eiJo48M4lwfkUO?usp=sharing\n",
    "#!pip install torchaudio\n",
    "import torch\n",
    "import numpy\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import soundfile\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
      "\r\u001B[K     |▏                               | 10kB 18.0MB/s eta 0:00:01\r\u001B[K     |▍                               | 20kB 25.9MB/s eta 0:00:01\r\u001B[K     |▌                               | 30kB 26.6MB/s eta 0:00:01\r\u001B[K     |▊                               | 40kB 18.1MB/s eta 0:00:01\r\u001B[K     |▉                               | 51kB 14.0MB/s eta 0:00:01\r\u001B[K     |█                               | 61kB 11.2MB/s eta 0:00:01\r\u001B[K     |█▏                              | 71kB 12.5MB/s eta 0:00:01\r\u001B[K     |█▍                              | 81kB 13.6MB/s eta 0:00:01\r\u001B[K     |█▌                              | 92kB 11.9MB/s eta 0:00:01\r\u001B[K     |█▊                              | 102kB 12.9MB/s eta 0:00:01\r\u001B[K     |█▉                              | 112kB 12.9MB/s eta 0:00:01\r\u001B[K     |██                              | 122kB 12.9MB/s eta 0:00:01\r\u001B[K     |██▏                             | 133kB 12.9MB/s eta 0:00:01\r\u001B[K     |██▍                             | 143kB 12.9MB/s eta 0:00:01\r\u001B[K     |██▌                             | 153kB 12.9MB/s eta 0:00:01\r\u001B[K     |██▊                             | 163kB 12.9MB/s eta 0:00:01\r\u001B[K     |██▉                             | 174kB 12.9MB/s eta 0:00:01\r\u001B[K     |███                             | 184kB 12.9MB/s eta 0:00:01\r\u001B[K     |███▏                            | 194kB 12.9MB/s eta 0:00:01\r\u001B[K     |███▍                            | 204kB 12.9MB/s eta 0:00:01\r\u001B[K     |███▌                            | 215kB 12.9MB/s eta 0:00:01\r\u001B[K     |███▊                            | 225kB 12.9MB/s eta 0:00:01\r\u001B[K     |███▉                            | 235kB 12.9MB/s eta 0:00:01\r\u001B[K     |████                            | 245kB 12.9MB/s eta 0:00:01\r\u001B[K     |████▏                           | 256kB 12.9MB/s eta 0:00:01\r\u001B[K     |████▍                           | 266kB 12.9MB/s eta 0:00:01\r\u001B[K     |████▌                           | 276kB 12.9MB/s eta 0:00:01\r\u001B[K     |████▊                           | 286kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████                           | 296kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████                           | 307kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████▎                          | 317kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████▍                          | 327kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████▋                          | 337kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████▊                          | 348kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████                          | 358kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████                          | 368kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████▎                         | 378kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████▍                         | 389kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████▋                         | 399kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████▊                         | 409kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████                         | 419kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████                         | 430kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████▎                        | 440kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████▍                        | 450kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████▋                        | 460kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████▊                        | 471kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████                        | 481kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████                        | 491kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████▎                       | 501kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████▍                       | 512kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████▋                       | 522kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████▊                       | 532kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████                       | 542kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████                       | 552kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████▎                      | 563kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████▌                      | 573kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████▋                      | 583kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████▉                      | 593kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████                      | 604kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████▏                     | 614kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████▎                     | 624kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████▌                     | 634kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████▋                     | 645kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████▉                     | 655kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████                     | 665kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████▏                    | 675kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████▎                    | 686kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████▌                    | 696kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████▋                    | 706kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████▉                    | 716kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████                    | 727kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████▏                   | 737kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████▎                   | 747kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████▌                   | 757kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████▋                   | 768kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████▉                   | 778kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████                   | 788kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████▏                  | 798kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████▎                  | 808kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████▌                  | 819kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████▋                  | 829kB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████▉                  | 839kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████                  | 849kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████▏                 | 860kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████▍                 | 870kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████▌                 | 880kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████▊                 | 890kB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████▉                 | 901kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████                 | 911kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████▏                | 921kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████▍                | 931kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████▌                | 942kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████▊                | 952kB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████▉                | 962kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████                | 972kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████▏               | 983kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████▍               | 993kB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████▌               | 1.0MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████▊               | 1.0MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████▉               | 1.0MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████               | 1.0MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████▏              | 1.0MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████▍              | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████▌              | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████▊              | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████▉              | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████              | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████▏             | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████▍             | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████▌             | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████▊             | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████             | 1.1MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████             | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████▎            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████▍            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████▋            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████▊            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████            | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████▎           | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████▍           | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████▋           | 1.2MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████▊           | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████           | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████           | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████▎          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████▍          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████▋          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████▊          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████          | 1.3MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████▎         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████▍         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████▋         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████▊         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████         | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████▎        | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████▌        | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████▋        | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████▉        | 1.4MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████        | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████▏       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████▎       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████▌       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████▋       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████▉       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████       | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▏      | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▎      | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▌      | 1.5MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▋      | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▉      | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████      | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▏     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▎     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▌     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▋     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▉     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████     | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▏    | 1.6MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▎    | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▌    | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▋    | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▉    | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████    | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▏   | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▍   | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▌   | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▊   | 1.7MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▉   | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████   | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▏  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▍  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▌  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▊  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▉  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████  | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▏ | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▍ | 1.8MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▌ | 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▊ | 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▉ | 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████ | 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▏| 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▍| 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▌| 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▊| 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▉| 1.9MB 12.9MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 1.9MB 12.9MB/s \n",
      "\u001B[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.8.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7O44zBGuhrX8"
   },
   "source": [
    "class SEBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=8):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=8):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(planes * 4, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, channel // reduction),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channel // reduction, channel),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9QFLOUpOhEa0"
   },
   "source": [
    "class PreEmphasis(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, coef: float = 0.97):\n",
    "        super().__init__()\n",
    "        self.coef = coef\n",
    "        # make kernel\n",
    "        # In pytorch, the convolution operation uses cross-correlation. So, filter is flipped.\n",
    "        self.register_buffer(\n",
    "            'flipped_filter', torch.FloatTensor([-self.coef, 1.]).unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.tensor) -> torch.tensor:\n",
    "        assert len(input.size()) == 2, 'The number of dimensions of input tensor must be 2!'\n",
    "        # reflect padding to match lengths of in/out\n",
    "        input = input.unsqueeze(1)\n",
    "        input = F.pad(input, (1, 0), 'reflect')\n",
    "        return F.conv1d(input, self.flipped_filter).squeeze(1)\n",
    "        \n",
    "class ResNetSE(nn.Module):\n",
    "    def __init__(self, block, layers, num_filters, nOut, encoder_type='SAP', n_mels=40, log_input=True, **kwargs):\n",
    "        super(ResNetSE, self).__init__()\n",
    "\n",
    "        print('Embedding size is %d, encoder %s.'%(nOut, encoder_type))\n",
    "        \n",
    "        self.inplanes   = num_filters[0]\n",
    "        self.encoder_type = encoder_type\n",
    "        self.n_mels     = n_mels\n",
    "        self.log_input  = log_input\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, num_filters[0] , kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn1 = nn.BatchNorm2d(num_filters[0])\n",
    "        \n",
    "\n",
    "        self.layer1 = self._make_layer(block, num_filters[0], layers[0])\n",
    "        self.layer2 = self._make_layer(block, num_filters[1], layers[1], stride=(2, 2))\n",
    "        self.layer3 = self._make_layer(block, num_filters[2], layers[2], stride=(2, 2))\n",
    "        self.layer4 = self._make_layer(block, num_filters[3], layers[3], stride=(2, 2))\n",
    "\n",
    "        self.instancenorm   = nn.InstanceNorm1d(n_mels)\n",
    "        self.torchfb        = torch.nn.Sequential(\n",
    "                PreEmphasis(),\n",
    "                torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=512, win_length=400, hop_length=160, window_fn=torch.hamming_window, n_mels=n_mels)\n",
    "                )\n",
    "\n",
    "        outmap_size = int(self.n_mels/8)\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(num_filters[3] * outmap_size, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, num_filters[3] * outmap_size, kernel_size=1),\n",
    "            nn.Softmax(dim=2),\n",
    "            )\n",
    "\n",
    "        if self.encoder_type == \"SAP\":\n",
    "            out_dim = num_filters[3] * outmap_size\n",
    "        elif self.encoder_type == \"ASP\":\n",
    "            out_dim = num_filters[3] * outmap_size * 2\n",
    "        else:\n",
    "            raise ValueError('Undefined encoder')\n",
    "\n",
    "        self.fc = nn.Linear(out_dim, nOut)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def new_parameter(self, *size):\n",
    "        out = nn.Parameter(torch.FloatTensor(*size))\n",
    "        nn.init.xavier_normal_(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                x = self.torchfb(x)+1e-6\n",
    "                if self.log_input: x = x.log()\n",
    "                x = self.instancenorm(x).unsqueeze(1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = x.reshape(x.size()[0],-1,x.size()[-1])\n",
    "\n",
    "        w = self.attention(x)\n",
    "\n",
    "        if self.encoder_type == \"SAP\":\n",
    "            x = torch.sum(x * w, dim=2)\n",
    "        elif self.encoder_type == \"ASP\":\n",
    "            mu = torch.sum(x * w, dim=2)\n",
    "            sg = torch.sqrt( ( torch.sum((x**2) * w, dim=2) - mu**2 ).clamp(min=1e-5) )\n",
    "            x = torch.cat((mu,sg),1)\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def MainModel(nOut=256, **kwargs):\n",
    "    # Number of filters\n",
    "    num_filters = [32, 64, 128, 256]\n",
    "    model = ResNetSE(SEBasicBlock, [3, 4, 6, 3], num_filters, nOut, **kwargs)\n",
    "    return model\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45mYBTbUduHW",
    "outputId": "70bd2fe3-7352-485e-a405-9d6b0662a8ce"
   },
   "source": [
    "model = MainModel(512, n_mels = 64, encoder_type='ASP')\n",
    "\n",
    "loaded_state = torch.load(\"baseline_v2_ap.model\", map_location=torch.device('cpu'))\n",
    "len_S = len('__S__.')\n",
    "\n",
    "d = loaded_state\n",
    "\n",
    "d1 = {}\n",
    "\n",
    "for k, v in d.items():\n",
    "    d1[k[len_S:]] = v\n",
    "d1.pop(\"softmax.fc.weight\")\n",
    "d1.pop(\"softmax.fc.bias\")\n",
    "d1.pop(\"angleproto.w\")\n",
    "d1.pop(\"angleproto.b\")\n",
    "model.load_state_dict(d1)\n",
    "model.eval()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Embedding size is 512, encoder ASP.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNetSE(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (torchfb): Sequential(\n",
       "    (0): PreEmphasis()\n",
       "    (1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "meD4efwCgnyi"
   },
   "source": [
    "def loadWAV(filename, max_frames, evalmode=True, num_eval=10):\n",
    "\n",
    "    # Maximum audio length\n",
    "    max_audio = max_frames * 160 + 240\n",
    "\n",
    "    # Read wav file and convert to torch tensor\n",
    "    audio, sample_rate = soundfile.read(filename)\n",
    "\n",
    "    audiosize = audio.shape[0]\n",
    "\n",
    "    if audiosize <= max_audio:\n",
    "        shortage    = max_audio - audiosize + 1 \n",
    "        audio       = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        audiosize   = audio.shape[0]\n",
    "\n",
    "    if evalmode:\n",
    "        startframe = numpy.linspace(0,audiosize-max_audio,num=num_eval)\n",
    "    else:\n",
    "        startframe = numpy.array([numpy.int64(random.random()*(audiosize-max_audio))])\n",
    "    \n",
    "    feats = []\n",
    "    if evalmode and max_frames == 0:\n",
    "        feats.append(audio)\n",
    "    else:\n",
    "        for asf in startframe:\n",
    "            feats.append(audio[int(asf):int(asf)+max_audio])\n",
    "\n",
    "    feat = numpy.stack(feats,axis=0).astype(numpy.float)\n",
    "\n",
    "    return feat;"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPOO4to9DzV_",
    "outputId": "7d8524c5-2d56-4de7-d28e-b70ef69192f3"
   },
   "source": [
    "#Trying to compare two speech fragments of the same person\n",
    "feat1 = []\n",
    "audio1 = loadWAV(\"female1.wav\", 400, evalmode=True)\n",
    "feat1.append(audio1)\n",
    "feat1 = numpy.concatenate(feat1, axis=0)\n",
    "tens1 = model.forward(torch.FloatTensor(feat1))\n",
    "\n",
    "feat2 = []\n",
    "audio2 = loadWAV(\"female2.wav\", 400, evalmode=True)\n",
    "feat2.append(audio2)\n",
    "feat2 = numpy.concatenate(feat2, axis=0)\n",
    "tens2 = model.forward(torch.FloatTensor(feat2))\n",
    "res1 = distance.cosine(numpy.mean(tens1.detach().numpy(), axis = 0), numpy.mean(tens2.detach().numpy(), axis = 0))\n",
    "txt = \"Distance for same person's speech case is {}\".format(str(res1))\n",
    "print(txt)\n",
    "\n",
    "#Trying to compare two speech fragments of different people\n",
    "feat3 = []\n",
    "audio3 = loadWAV(\"male1.wav\", 400, evalmode=True)\n",
    "feat3.append(audio3)\n",
    "feat3 = numpy.concatenate(feat3, axis=0)\n",
    "tens3 = model.forward(torch.FloatTensor(feat3))\n",
    "\n",
    "res2 = distance.cosine(numpy.mean(tens1.detach().numpy(), axis = 0), numpy.mean(tens3.detach().numpy(), axis = 0))\n",
    "txt = \"Distance for different people's speech case is {}\".format(str(res2))\n",
    "print(txt)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Distance for same person's speech case is 0.03420382738113403\n",
      "Distance for different people's speech case is 0.32118064165115356\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UsLFp1lXlEVw"
   },
   "source": [
    "class test_dataset_loader(Dataset):\n",
    "    def __init__(self, test_list, test_path, eval_frames, num_eval, **kwargs):\n",
    "        self.max_frames = eval_frames;\n",
    "        self.num_eval = num_eval\n",
    "        self.test_path = test_path\n",
    "        self.test_list = test_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio = loadWAV(os.path.join(self.test_path, self.test_list[index]), 400, evalmode=True)\n",
    "        return torch.FloatTensor(audio), self.test_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_list)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluateFromList(model, test_list, test_path, nDataLoaderThread, print_interval=100, num_eval=10, **kwargs):\n",
    "    rank = 0\n",
    "\n",
    "    lines = []\n",
    "    files = []\n",
    "    feats = {}\n",
    "    ## Read all lines\n",
    "    with open(test_list) as f:\n",
    "        lines = f.readlines()\n",
    "    ## Get a list of unique file names\n",
    "    files = list(itertools.chain(*[x.strip().split()[-2:] for x in lines]))\n",
    "    setfiles = list(set(files))\n",
    "    setfiles.sort()\n",
    "    ## Define test data loader\n",
    "    test_dataset = test_dataset_loader(setfiles, test_path, 2, num_eval=2, **kwargs)\n",
    "    sampler = None\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    ## Extract features for every image\n",
    "    for idx, data in enumerate(test_loader):\n",
    "        print('HERE10')\n",
    "        inp1 = data[0][0]\n",
    "        inp2 = data[1][0]\n",
    "        feat1 = []\n",
    "        feat1.append(inp1)\n",
    "        ref_feat = numpy.concatenate(feat1, axis=0)\n",
    "\n",
    "        feats[data[1][0]] = ref_feat\n",
    "\n",
    "    all_scores = [];\n",
    "    all_labels = [];\n",
    "    all_trials = [];\n",
    "\n",
    "    if rank == 0:\n",
    "\n",
    "        ## Read files and compute all scores\n",
    "        for idx, line in enumerate(lines):\n",
    "\n",
    "            data = line.split();\n",
    "\n",
    "            ref_feat = feats[data[1]]\n",
    "            com_feat = feats[data[2]]\n",
    "            tensRef = model.forward(torch.FloatTensor(ref_feat))\n",
    "            tensCom = model.forward(torch.FloatTensor(com_feat))\n",
    "\n",
    "            dist = distance.cosine(numpy.mean(tensRef.detach().numpy(), axis=0),\n",
    "                                   numpy.mean(tensCom.detach().numpy(), axis=0))\n",
    "\n",
    "            score = dist\n",
    "\n",
    "            all_scores.append(score)\n",
    "            all_labels.append(int(data[0]))\n",
    "\n",
    "    return (all_scores, all_labels);\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores, labels = evaluateFromList(model, \"test_list1.txt\", \"vox1_test_wav/wav\", 5)\n",
    "scores = np.array(scores)\n",
    "labels = np.array(labels)\n",
    "boolLabels = labels > 0\n",
    "plotArr = numpy.array([labels, scores]).transpose()\n",
    "plotArr0 = scores[boolLabels == False]\n",
    "plotArr1 = scores[boolLabels]\n",
    "\n",
    "bins = numpy.linspace(0, 1.5, 2000)\n",
    "pyplot.hist(plotArr0, density=True, bins=bins, label='False')\n",
    "pyplot.hist(plotArr1, density=True, bins=bins, label='True')\n",
    "pyplot.ylabel('Amount of samples')\n",
    "pyplot.xlabel('Distance');\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}